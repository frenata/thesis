It appears that data visualization has had limited penetration into educational circles; similar and illuminating is a self-published article by Lisa Spiro, of Rice University. Ultimately expressing skepticism that a submission to an academic journal full of charts and tables of text analysis would be given much interest or even understood, Spiro strongly argues that such analysis can "inform the kind of arguments critics make". In other words, using analytical tools as a complement to expert judgement and experience can provoke entirely new kinds of discussions. Very quickly into her exploration of visualization technologies, Spiro becomes frustrated with the relative lack of power in the tools at her disposal. But even limited tools can help confirm or deny the more common qualitative analysis. Spiro also makes the divide between text analysis and text visualization stark, finding that while hard numbers were more trustworthy, visual impressions "opened my eyes so that I could see the stats more meaningfully."

Nualart-Vilaplana's study of the variety of approaches to text visualization makes this same point with the backing of data: the evidence indicates that information-retention is increased by a "combination of text and illustration." Their study explores the history of the field, attempting to catalogue these techniques. Noting that organizations are in fact _flooded_ with data, they argue for several key factors when selecting a visualization technique. First, because of the amount of data involved, searching for the relevant data must inevitably be a central concern. Second, even when search turns up the correct data, the search results must be presented in such a way as to simplify selecting the right data. Done correctly, searching through massive data can allow for the discovery of new information, possibly even information that could not have been identified without aggregation techniques.

As a practial matter, most data is simple unstructured text, rather than highly structured JSON or XML that is already easily searchable. This unstructured text must have its information extracted to be usable. Miner discusses the two primary approaches: _rule-based_ analysis or _statistical_ analysis. For semi-structured texts such as templated Microsoft Word documents, a rule-based approach seems superior, since the structural elements that do exist can be converted into rules for extraction.

A final insight from Nualart-Vilaplana's study is highly relevant when examining the various tools and techniques that can be used to implement data visualization. For software solutions that dated more than 5 years old, the vast majority of software was simple no longer available. As no organzation should want to either continually change their technology solutions or to be stuck self-supporting legacy solutions, this remains a serious question. No particular cause is offered up, but it is indicated that they found a correlation between commerial software and abandoned software.

