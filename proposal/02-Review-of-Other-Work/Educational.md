* discuss need for measuring alignment
* examine current tools

### Carpinelli et al
* Standards are common now (2), and much effort has been spent on developing standards-based curriculum and testing,  but does this translate into standards-based lesson planning?
* Common problems with lesson plans (4)
 * Too many standards/wrong standards
 * Learning objective not related to lesson or standard
 * Assesment is not related to learning objective or standard
* Most techniques to measure effectiveness of lesson plans are related to teacher efficacy (5)
* Authors developed a rubric to evaluate lesson plans (6)
* Gave 200 plans to a panel, but inter-rater reliability was weak. (7)

### Torff
* demand for more teachers has led to alternative teacher certification routes, so how can "competence" be determined?
 * to do this via quantitative means? (test scores)
 * or qualitative (supervisor perception)
* principal evaluations (and of course any eval) is "subjective, potentially biased, and may differ from actual causes"

### Avery
* Program evaluations (of gifted student programs) is limited, and is the data used?
* accountability is only theoretical?
* "absence of data on student learning"
* in interviews with stakeholders, often complaints about lack of data


Numerical data may once have been irrelevant in the halls of academia and the bustling classrooms full of students, but in an era that increasingly emphasizes written *standards* over tradition, this is no longer desirable. (Carpinelli 2) If standards were designed to create equitable student outcomes across different schools or areas, how are educators to know whether their goal has been met? Evaluation of standards-based programs may be desirable but impossible due to lack of data availability. Although great effort has been spent on preparing standards-based curriculum and standards-based testing strategies, Carpinelli et al question whether this effort has translated into lesson plans that teachers generate on a daily basis. (2) Thus, the aim of this project is to examine these ground-level documents that may represent the closest data to the act of teaching itself.

But why is evaluation necessary? In previous studies, two primary reasons for evaluation occur: to identify teacher efficacy in educating students, and to identify learning outcomes of students themselves.

Torff puts plainly why it is necessary to evaluate teacher efficacy: the increasing demand for teachers is not being supplied by traditional avenues, so a variety of alternative pipelines for producing certified teachers have emerged. Whether these pipelines are producing effective teachers is unclear. There are two main approaches to assesing teacher effectiveness: quantitative and qualitative. The quantitative approach has generally meant reducing teachers to a collection of student test grades. The qualitative approach gives principals and other supervisors the task of assesing teacher competence, but potential bias reigns. Torff leaves undiscussed the idea of quantitively assesing teacher's on the basis of their actual output rather than student success.

At least as important as evaluating teachers is evalutating student outcomes, but in some instances the desired accountability is merely theoretical. Avery laments the simple "absence of data on student learning" in the context of gifted learning programs. While it is suggested that states may simply be focusing on the larger body of students, if states cannot make data-driven decisions in the context of a relatively small program, how can they hope to do so as scale dramatically increases? And this is not a forgotten issue: in interviews with various stakeholders, a consistent complaint was the lack of available data.

One of the few attempts to look at bottom-up data is Carpinelli. In their study, they developed a rubric-based grading model for lesson plans and recruited and trained a panel to evaluate 200 lesson plans from a variety of sources. They identified several common problems across lesson plans: the use of too many or incorrect standards, lesson objectives that simply do not correlate to stated standards, and assesments that do not correlate it either standards or objectives. Unfortunately, the inter-rater agreement on which lesson plans were poor was weak.

What are schools to make of the lack of data, the lack of good ways to interpret it, or the lack of willingness to use it? As it turns out, how to use data to drive decision making has long been a focus of the corporate world, where it is often discussed as "Business Intelligence."
